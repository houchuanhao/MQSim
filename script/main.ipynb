{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8314c615",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/bin/python\n",
      "collection:  472\n",
      "collection:  1774\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/lib/python3.9/site-packages/openpyxl/reader/excel.py:237: UserWarning: Data Validation extension is not supported and will be removed\n",
      "  ws_parser.bind_all()\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from script.tools import tools\n",
    "from script.collection import Parameter as pmt\n",
    "import sys\n",
    "print(sys.executable)\n",
    "import net\n",
    "import os\n",
    "from script.tools import collection\n",
    "result = collection.collection(\"collection/workspace1\")  #[iops,dic_ssd,dic_worload,f.path]\n",
    "result = collection.collection(\"collection/workspace2\",result)\n",
    "plst = collection.getParameters(path=\"collection/config.xlsx\",id = \"1\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1714   1714\n",
      "48\n"
     ]
    }
   ],
   "source": [
    "xlst = []\n",
    "ylst = []\n",
    "xylst = []\n",
    "keys = []\n",
    "expect = ['Seed','key','default']\n",
    "for iops,dic_ssd,dic_worload,path in result:\n",
    "    dic = dic_ssd\n",
    "    dic.update(dic_worload)\n",
    "    values,keys = collection.getUsefullKeys(dic,plst,expect)\n",
    "    if iops == 'inf':\n",
    "        #print(\"inf------\")\n",
    "        continue\n",
    "    xlst.append(values)\n",
    "    ylst.append([float(iops)])\n",
    "    xylst.append([values,[float(iops)]])\n",
    "    keys = keys\n",
    "print(len(xlst),\" \",len(ylst))\n",
    "print(len(xlst[0]))\n",
    "#print(keys)\n",
    "#print(ylst)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "09460b96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1714, 48]) torch.Size([1714, 1])\n",
      "torch.Size([2, 3])\n",
      "PCIe_Lane_Bandwidth default:  1.00000  mean: 2.0686001777648926  std： 2.269704580307007\n",
      "PCIe_Lane_Count default:  4  mean: 19.761960983276367  std： 11.245830535888672\n",
      "SATA_Processing_Delay default:  400000  mean: 2025643.125  std： 1128192.875\n",
      "Queue_Fetch_Size default:  512  mean: 2582.690673828125  std： 1467.95458984375\n",
      "Data_Cache_DRAM_Row_Size default:  8192  mean: 40766.30078125  std： 23435.74609375\n",
      "Data_Cache_DRAM_Data_Rate default:  100  mean: 503.1376953125  std： 285.00799560546875\n",
      "Data_Cache_DRAM_Data_Busrt_Size default:  1  mean: 5.575262546539307  std： 2.9104950428009033\n",
      "Data_Cache_DRAM_tRCD default:  13  mean: 65.455078125  std： 37.691986083984375\n",
      "Data_Cache_DRAM_tCL default:  13  mean: 64.97899627685547  std： 37.967872619628906\n",
      "Data_Cache_DRAM_tRP default:  13  mean: 64.94457244873047  std： 37.416290283203125\n",
      "Overprovisioning_Ratio default:  0.07  mean: 0.18851685523986816  std： 0.1502837985754013\n",
      "GC_Exec_Threshold default:  0.05000  mean: 0.2560892403125763  std： 0.1444678008556366\n",
      "Preferred_suspend_erase_time_for_read default:  700000  mean: 3603327.75  std： 2014349.125\n",
      "Preferred_suspend_erase_time_for_write default:  700000  mean: 3506851.75  std： 2021351.625\n",
      "Preferred_suspend_write_time_for_read default:  100000  mean: 507965.84375  std： 282182.96875\n",
      "Flash_Channel_Count default:  8  mean: 13.38681411743164  std： 17.306489944458008\n",
      "Flash_Channel_Width default:  1  mean: 5.555426120758057  std： 2.8703482151031494\n",
      "Channel_Transfer_Rate default:  333  mean: 1699.3616943359375  std： 940.759521484375\n",
      "Chip_No_Per_Channel default:  4  mean: 8.700699806213379  std： 9.286120414733887\n",
      "Page_Read_Latency_LSB default:  75000  mean: 380384.21875  std： 215358.234375\n",
      "Page_Read_Latency_CSB default:  75000  mean: 381173.0625  std： 212378.953125\n",
      "Page_Read_Latency_MSB default:  75000  mean: 385452.1875  std： 215981.71875\n",
      "Page_Program_Latency_LSB default:  750000  mean: 3831699.0  std： 2145928.0\n",
      "Page_Program_Latency_CSB default:  750000  mean: 3791195.75  std： 2149922.25\n",
      "Page_Program_Latency_MSB default:  750000  mean: 3831433.75  std： 2136177.0\n",
      "Block_Erase_Latency default:  3800000  mean: 19039548.0  std： 11001904.0\n",
      "Block_PE_Cycles_Limit default:  10000  mean: 49755.984375  std： 28522.791015625\n",
      "Suspend_Erase_Time default:  700000  mean: 3556321.0  std： 2007380.875\n",
      "Suspend_Program_Time default:  100000  mean: 502363.78125  std： 284812.0625\n",
      "Die_No_Per_Chip default:  2  mean: 7.422403812408447  std： 7.8372297286987305\n",
      "Plane_No_Per_Die default:  2  mean: 7.823220729827881  std： 8.127969741821289\n",
      "Block_No_Per_Plane default:  2048  mean: 4389.61474609375  std： 4955.72021484375\n",
      "Page_No_Per_Block default:  256  mean: 514.468505859375  std： 615.0591430664062\n",
      "Page_Capacity default:  8192  mean: 16667.5703125  std： 19150.44921875\n",
      "Page_Metadat_Capacity default:  448  mean: 2241.0927734375  std： 1263.2899169921875\n",
      "Channel_IDs default:  0,1,2,3,4,5,6,7  mean: 6.779463291168213  std： 9.79869270324707\n",
      "Chip_IDs default:  0,1,2,3  mean: 4.839556694030762  std： 5.909952640533447\n",
      "Die_IDs default:  0,1  mean: 4.089848518371582  std： 4.8169145584106445\n",
      "Plane_IDs default:  0,1  mean: 4.415986061096191  std： 5.1680684089660645\n",
      "Initial_Occupancy_Percentage default:  75  mean: 50.01866912841797  std： 28.861339569091797\n",
      "Working_Set_Percentage default:  50  mean: 49.66102600097656  std： 29.57884979248047\n",
      "Read_Percentage default:  50  mean: 48.3809814453125  std： 28.936250686645508\n",
      "Percentage_of_Hot_Region default:  0  mean: 50.603851318359375  std： 29.657630920410156\n",
      "Address_Alignment_Unit default:  16  mean: 79.94632720947266  std： 47.032989501953125\n",
      "Average_Request_Size default:  8  mean: 40.09393310546875  std： 22.833797454833984\n",
      "Variance_Request_Size default:  0  mean: 488.348876953125  std： 297.0753479003906\n",
      "Average_No_of_Reqs_in_Queue default:  16  mean: 83.52625274658203  std： 46.15544891357422\n",
      "Intensity default:  32768  mean: 167254.25  std： 93899.8828125\n"
     ]
    }
   ],
   "source": [
    "x_tensor = torch.tensor(xlst,dtype=torch.float)\n",
    "y_tensor = torch.tensor(ylst,dtype=torch.float)\n",
    "print(x_tensor.size(),y_tensor.size())\n",
    "tensor1 = torch.tensor([[1, 2, 3],\n",
    "                       [4, 5, 6]])\n",
    "print(tensor1.size())\n",
    "#x_ytensor = torch.tensor(xylst,dtype=torch.float)\n",
    "\n",
    "\n",
    "# 计算均值和标准差\n",
    "x_mean = x_tensor.mean(dim=0)\n",
    "x_std = x_tensor.std(dim=0)\n",
    "y_mean = y_tensor.mean(dim=0)\n",
    "y_std = y_tensor.std(dim=0)\n",
    "\n",
    "# 归一化 x 和 y\n",
    "normalized_x = (x_tensor - x_mean) / x_std\n",
    "normalized_y = (y_tensor - y_mean) / y_std\n",
    "normalized_y_std = y_tensor  / y_std\n",
    "#print(\"x_mean: \",x_mean)\n",
    "#print(\"x_std: \",x_std)\n",
    "#print(\"y_mean: \",y_mean)\n",
    "#print(\"y_std: \",y_std)\n",
    "#print(x_tensor[0])\n",
    "#print(keys)\n",
    "\n",
    "tree_ssd,rootssd = tools.getTree(\"collection/ssdconfig.xml\")\n",
    "tree_workload,root_workload = tools.getTree(\"collection/workload.xml\")\n",
    "i = 0\n",
    "for key in keys:\n",
    "    default = tools.getext(rootssd,key)\n",
    "    if default == None:\n",
    "        default = tools.getext(root_workload,key)\n",
    "    print(key,\"default: \", default,\" mean:\",str(x_mean[i].item()),\" std：\",x_std[i].item())\n",
    "    i = i + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "model = net.DeepNet(48,48,1,5)\n",
    "#device = torch.device(\"mps\")\n",
    "#device = torch.device(\"cpu\")\n",
    "#model.to(device)\n",
    "criterion = nn.MSELoss()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.optim as optim\n",
    "# 自定义数据集类\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, x, y):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.x[idx], self.y[idx]\n",
    "\n",
    "# dataset = CustomDataset(x_tensor, y_tensor)\n",
    "y_modified = y_tensor/y_mean\n",
    "dataset = CustomDataset(normalized_x, y_modified)\n",
    "batch_size = 5\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "#optimizer = optim.SGD(model.parameters(), lr=0.001)\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/1000], Loss: 0.0038\n",
      "Epoch [20/1000], Loss: 0.0055\n",
      "Epoch [30/1000], Loss: 0.0047\n",
      "Epoch [40/1000], Loss: 0.0040\n",
      "Epoch [50/1000], Loss: 0.0048\n",
      "Epoch [60/1000], Loss: 0.0022\n",
      "Epoch [70/1000], Loss: 0.0024\n",
      "Epoch [80/1000], Loss: 0.0037\n",
      "Epoch [90/1000], Loss: 0.0061\n",
      "Epoch [100/1000], Loss: 0.0019\n",
      "Epoch [110/1000], Loss: 0.0052\n",
      "Epoch [120/1000], Loss: 0.0071\n",
      "Epoch [130/1000], Loss: 0.0066\n",
      "Epoch [140/1000], Loss: 0.0034\n",
      "Epoch [150/1000], Loss: 0.0036\n",
      "Epoch [160/1000], Loss: 0.0035\n",
      "Epoch [170/1000], Loss: 0.0031\n",
      "Epoch [180/1000], Loss: 0.0025\n",
      "Epoch [190/1000], Loss: 0.0041\n",
      "Epoch [200/1000], Loss: 0.0036\n",
      "Epoch [210/1000], Loss: 0.0036\n",
      "Epoch [220/1000], Loss: 0.0081\n",
      "Epoch [230/1000], Loss: 0.0050\n",
      "Epoch [240/1000], Loss: 0.0031\n",
      "Epoch [250/1000], Loss: 0.0043\n",
      "Epoch [260/1000], Loss: 0.0031\n",
      "Epoch [270/1000], Loss: 0.0044\n",
      "Epoch [280/1000], Loss: 0.0021\n",
      "Epoch [290/1000], Loss: 0.0040\n",
      "Epoch [300/1000], Loss: 0.0036\n",
      "Epoch [310/1000], Loss: 0.0016\n",
      "Epoch [320/1000], Loss: 0.0024\n",
      "Epoch [330/1000], Loss: 0.0020\n",
      "Epoch [340/1000], Loss: 0.0024\n",
      "Epoch [350/1000], Loss: 0.0027\n",
      "Epoch [360/1000], Loss: 0.0023\n",
      "Epoch [370/1000], Loss: 0.0047\n",
      "Epoch [380/1000], Loss: 0.0013\n",
      "Epoch [390/1000], Loss: 0.0032\n",
      "Epoch [400/1000], Loss: 0.0026\n",
      "Epoch [410/1000], Loss: 0.0016\n",
      "Epoch [420/1000], Loss: 0.0029\n",
      "Epoch [430/1000], Loss: 0.0013\n",
      "Epoch [440/1000], Loss: 0.0033\n",
      "Epoch [450/1000], Loss: 0.0043\n",
      "Epoch [460/1000], Loss: 0.0037\n",
      "Epoch [470/1000], Loss: 0.0019\n",
      "Epoch [480/1000], Loss: 0.0038\n",
      "Epoch [490/1000], Loss: 0.0020\n",
      "Epoch [500/1000], Loss: 0.0020\n",
      "Epoch [510/1000], Loss: 0.0020\n",
      "Epoch [520/1000], Loss: 0.0039\n",
      "Epoch [530/1000], Loss: 0.0028\n",
      "Epoch [540/1000], Loss: 0.0020\n",
      "Epoch [550/1000], Loss: 0.0028\n",
      "Epoch [560/1000], Loss: 0.0015\n",
      "Epoch [570/1000], Loss: 0.0025\n",
      "Epoch [580/1000], Loss: 0.0031\n",
      "Epoch [590/1000], Loss: 0.0026\n",
      "Epoch [600/1000], Loss: 0.0012\n",
      "Epoch [610/1000], Loss: 0.0022\n",
      "Epoch [620/1000], Loss: 0.0014\n",
      "Epoch [630/1000], Loss: 0.0015\n",
      "Epoch [640/1000], Loss: 0.0032\n",
      "Epoch [650/1000], Loss: 0.0022\n",
      "Epoch [660/1000], Loss: 0.0022\n",
      "Epoch [670/1000], Loss: 0.0048\n",
      "Epoch [680/1000], Loss: 0.0024\n",
      "Epoch [690/1000], Loss: 0.0033\n",
      "Epoch [700/1000], Loss: 0.0014\n",
      "Epoch [710/1000], Loss: 0.0013\n",
      "Epoch [720/1000], Loss: 0.0019\n",
      "Epoch [730/1000], Loss: 0.0026\n",
      "Epoch [740/1000], Loss: 0.0030\n",
      "Epoch [750/1000], Loss: 0.0021\n",
      "Epoch [760/1000], Loss: 0.0015\n",
      "Epoch [770/1000], Loss: 0.0019\n",
      "Epoch [780/1000], Loss: 0.0031\n",
      "Epoch [790/1000], Loss: 0.0018\n",
      "Epoch [800/1000], Loss: 0.0025\n",
      "Epoch [810/1000], Loss: 0.0013\n",
      "Epoch [820/1000], Loss: 0.0012\n",
      "Epoch [830/1000], Loss: 0.0020\n",
      "Epoch [840/1000], Loss: 0.0016\n",
      "Epoch [850/1000], Loss: 0.0021\n",
      "Epoch [860/1000], Loss: 0.0017\n",
      "Epoch [870/1000], Loss: 0.0025\n",
      "Epoch [880/1000], Loss: 0.0013\n",
      "Epoch [890/1000], Loss: 0.0016\n",
      "Epoch [900/1000], Loss: 0.0022\n",
      "Epoch [910/1000], Loss: 0.0037\n",
      "Epoch [920/1000], Loss: 0.0011\n",
      "Epoch [930/1000], Loss: 0.0027\n",
      "Epoch [940/1000], Loss: 0.0024\n",
      "Epoch [950/1000], Loss: 0.0020\n",
      "Epoch [960/1000], Loss: 0.0016\n",
      "Epoch [970/1000], Loss: 0.0039\n",
      "Epoch [980/1000], Loss: 0.0027\n",
      "Epoch [990/1000], Loss: 0.0027\n",
      "Epoch [1000/1000], Loss: 0.0014\n"
     ]
    }
   ],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "num_epochs = 1000\n",
    "\n",
    "loss_history = []\n",
    "for epoch in range(num_epochs):\n",
    "    total_loss = 0.0\n",
    "    i = 0\n",
    "    for batch_x, batch_y in dataloader:\n",
    "        #print(\"hhhh \")\n",
    "        #print(batch_x,batch_x)\n",
    "        #i = i +1\n",
    "        #print(batch_x,\"\\n\",batch_y)\n",
    "        #print(\"zzzzzzz\")\n",
    "        # 前向传播\n",
    "\n",
    "        outputs = model(batch_x)\n",
    "        #print(\"batch_x\",batch_x[0],\"\\n outputs: \",outputs[0])\n",
    "        loss = criterion(outputs, batch_y)\n",
    "        i = i +1\n",
    "        if i == -1:\n",
    "            print(\"i=------\"+str(i),\"\\n outputs: \",outputs,\"\\n y:\",batch_y)\n",
    "        total_loss += loss.item()\n",
    "        if False:\n",
    "            print(\"   \\n \\n\")\n",
    "            print(\" outputs: \", outputs)\n",
    "            print(\" batch_y\", batch_y)\n",
    "            print(\" loss \", loss)\n",
    "\n",
    "            print(\"   \\n \\n\")\n",
    "        #print(f'Epoch [{epoch+1}/{num_epochs}]')\n",
    "        #print(\"loss:\",loss.item(),\"batch_x: \",batch_x,\" outputs \",outputs,\" batch_y: \",batch_y)\n",
    "        # 反向传播和优化\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    #loss_history.append(total_loss)\n",
    "    # 打印训练信息\n",
    "    if (epoch+1) % 10 == 0:\n",
    "        average_loss = total_loss / len(dataloader)\n",
    "        #print(f'Epoch [{epoch+1}/{num_epochs}]')\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {average_loss:.4f}')\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1561, grad_fn=<DivBackward0>)\n",
      "1111111\n",
      "tensor(0.1561, grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "y_predict_train = model(normalized_x)\n",
    "y_err = (y_predict_train - y_modified)/y_modified\n",
    "print(torch.sum(abs(y_err))/len(y_predict))\n",
    "\n",
    "def test(x_,y_,m,rate_y, mean_x = 0,std_x = 1):\n",
    "    x_ = (x_ - mean_x)/std_x\n",
    "    y_pre = m(x_)*rate_y\n",
    "    y_e = abs(y_pre - y_)/y_\n",
    "    print(torch.sum(y_e)/len(y_))\n",
    "# 训练集\n",
    "test(x_tensor,y_tensor,model,y_mean,x_mean,x_std);\n",
    "# 测试集\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "collection:  1070\n"
     ]
    }
   ],
   "source": [
    "result1 = []\n",
    "result1 = collection.collection(\"collection/workspace\",result1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%s\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48\n",
      "['PCIe_Lane_Bandwidth', 'PCIe_Lane_Count', 'SATA_Processing_Delay', 'Queue_Fetch_Size', 'Data_Cache_DRAM_Row_Size', 'Data_Cache_DRAM_Data_Rate', 'Data_Cache_DRAM_Data_Busrt_Size', 'Data_Cache_DRAM_tRCD', 'Data_Cache_DRAM_tCL', 'Data_Cache_DRAM_tRP', 'Overprovisioning_Ratio', 'GC_Exec_Threshold', 'Preferred_suspend_erase_time_for_read', 'Preferred_suspend_erase_time_for_write', 'Preferred_suspend_write_time_for_read', 'Flash_Channel_Count', 'Flash_Channel_Width', 'Channel_Transfer_Rate', 'Chip_No_Per_Channel', 'Page_Read_Latency_LSB', 'Page_Read_Latency_CSB', 'Page_Read_Latency_MSB', 'Page_Program_Latency_LSB', 'Page_Program_Latency_CSB', 'Page_Program_Latency_MSB', 'Block_Erase_Latency', 'Block_PE_Cycles_Limit', 'Suspend_Erase_Time', 'Suspend_Program_Time', 'Die_No_Per_Chip', 'Plane_No_Per_Die', 'Block_No_Per_Plane', 'Page_No_Per_Block', 'Page_Capacity', 'Page_Metadat_Capacity', 'Channel_IDs', 'Chip_IDs', 'Die_IDs', 'Plane_IDs', 'Initial_Occupancy_Percentage', 'Working_Set_Percentage', 'Read_Percentage', 'Percentage_of_Hot_Region', 'Address_Alignment_Unit', 'Average_Request_Size', 'Variance_Request_Size', 'Average_No_of_Reqs_in_Queue', 'Intensity']\n",
      "lst2excel test.xlsx\n"
     ]
    }
   ],
   "source": [
    "#print(xlst[0])\n",
    "print(len(xlst[0]))\n",
    "tx = []\n",
    "tx.append(keys)\n",
    "i = 0\n",
    "for y_ in ylst:\n",
    "    x_ = xlst[i].copy()\n",
    "    x_.append(y_[0])\n",
    "    tx.append(x_)\n",
    "    i = i + 1\n",
    "print(tx[0])\n",
    "tools.lst2excel(tx,\"test.xlsx\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48\n",
      "Python版本: 3.9.13\n"
     ]
    }
   ],
   "source": [
    "print(len(keys))\n",
    "import platform\n",
    "\n",
    "print(\"Python版本:\", platform.python_version())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
